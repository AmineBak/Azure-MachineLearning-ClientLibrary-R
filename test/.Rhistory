foundpathindex = pathno
break
}
}
}
}
}
executepath = names(swagger$paths)[[foundpathindex]]
httpMethod = toupper(names(swagger$paths[[2]]))
# requestURL:
#   "https://requestresponse001.cloudapp.net:443/workspaces/7e8f135f31274b7eac419bd056875c03/services/a5b003e52c924d16a2e38ade45dd0154/execute?api-version=2.0&format=swagger"
#   schemes://hostbasepath(path where operationId="execute")
requestURL = paste(schemes,"://", host, "/workspaces/", wkID, "/services/", token, executepath, sep = "")
httpRequest = paste(httpMethod,requestURL)
#tell user what they can do
if(foundExec) {
consumefile = paste("consumeFile(api_key, requestURL, dataframe)")
consumedf = paste("consumeDataframe(api_key, requestURL, valuesDF)")
consumelists = paste("consumeLists(api_key, requestURL, ...)")
consumedt = paste("consumeFile(api_key, requestURL, columnNames, ...)")
cat("Sample functions to execute the web service and get a response synchronously:","\n", consumefile,"\n", consumedf,"\n", consumelists,"\n", consumedt,"\n","\n")
}
return (list("Request URL:" = requestURL, "Sample input:" = inputexample, "Input schema:" = inputschema))
}
setwd("C://Users/t-alewa/Documents/Azure-MachineLearning-ClientLibrary-R/demo")
wsID = "3612640f27234eb7b2b91ac62e8b4a40"
wsAuth = "abcbe14a958a40978f93aa0e0e71f5be"
test <- read.csv(file="test.csv")
train <- read.csv(file="train.csv")
head(test)
head(train)
#y variable
survived <- train$Survived
#id
passengerId <- test$PassengerId
#remove from the training sample
train = train[,-2]
end_trn = nrow(train)
#combine the two sets
train <- rbind(train, test)
#Age replace with mean
train$Age[is.na(train$Age)] <- 30
end = nrow(train)
#remove columns
train = train[,c(-1,-3,-8,-10,-11)]
head(train)
library(gbm)
set.seed(123)
pr=0
tr=0
n.models = 5
ntrees=2000
# train a generalized boosted regression model
for(i in 1:n.models){
GBM.model = gbm.fit(
x=train[1:end_trn,], y = survived,
distribution= "gaussian",
n.trees = ntrees,
shrinkage = 0.01,
interaction.depth = 25,
n.minobsinnode = 5,
verbose = TRUE)
#test set prediction
pr1 = predict.gbm(object=GBM.model,newdata=train[(end_trn+1):end,], ntrees)
#training set prediction
tr1 = predict.gbm(object = GBM.model,newdata=train[1:end_trn,], ntrees)
pr = pr+pr1
tr = tr+tr1
}
pr = pr/n.models
tr = tr/n.modelsti
head(pr)
head(tr)
summary(GBM.model)
pr = round(pr)
tr = round(tr)
# create a function to make predictions using the trained model
predictTitanic <- function (Pclass, Sex, Age, SibSp, Parch, Fare) {
return(predict.gbm(object=GBM.model, newdata=data.frame("Pclass"=Pclass, "Sex"=Sex, "Age"=Age, "SibSp"=SibSp, "Parch"=Parch, "Fare"=Fare), 2000))
}
predictTitanic(1, "male", 20, 2, 0, 8.50)
TitanicService <- publishWebService("predictTitanic", "TitanicDemo", list("Pclass"="string", "Sex"="string", "Age"="int", "SibSp"="int", "Parch"="int", "Fare"="float"), list("survProb"="float"), wsID, wsAuth)
endpoints <- TitanicService[[2]]
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""), list("Pclass", "Sex", "Age", "SibSp", "Parch", "Fare"), list("1", "male", "20", "2", "0", "8.50"), list("1", "female", "20", "1", "0", "8.50"))
response
predictTitanic(1, "male", 20, 2, 0, 8.50)
demoDF <- data.frame("Pclass"=c(1,2,1), "Sex"=c("male","female","male"), "Age"=c("8","20", "30"), "Parch"=c(1,1,1), "SibSp"=c(1,3,1), "Fare"=c(10,7.5, 9))
responseDF <- consumeDataframe(TitanicService[[2]][[1]]$PrimaryKey, paste(TitanicService[[2]][[1]]$ApiLocation,"/execute?api-version=2.0&details=true",sep=""), demoDF)
responseDF
setwd("C://Users/t-alewa/Documents/Azure-MachineLearning-ClientLibrary-R/demo")
#setwd("C://Users/t-ritra/Documents/Github/Azure-MachineLearning-ClientLibrary-R/demo")
# test server
wsID = "bbc91d900c3546b695d6507867fc72ae"
wsAuth = "ffc4b8d52c494e9eb42726b77112be88"
# internal server
wsID = "3612640f27234eb7b2b91ac62e8b4a40"
wsAuth = "abcbe14a958a40978f93aa0e0e71f5be"
#
test <- read.csv(file="test.csv")
train <- read.csv(file="train.csv")
head(test)
head(train)
#y variable
survived <- train$Survived
#id
passengerId <- test$PassengerId
#remove from the training sample
train = train[,-2]
end_trn = nrow(train)
#combine the two sets
train <- rbind(train, test)
#Age replace with mean
train$Age[is.na(train$Age)] <- 30
end = nrow(train)
#remove columns
train = train[,c(-1,-3,-8,-10,-11)]
head(train)
library(gbm)
set.seed(123)
pr=0
tr=0
n.models = 5
ntrees=2000
# train a generalized boosted regression model
for(i in 1:n.models){
GBM.model = gbm.fit(
x=train[1:end_trn,], y = survived,
distribution= "gaussian",
n.trees = ntrees,
shrinkage = 0.01,
interaction.depth = 25,
n.minobsinnode = 5,
verbose = TRUE)
#test set prediction
pr1 = predict.gbm(object=GBM.model,newdata=train[(end_trn+1):end,], ntrees)
#training set prediction
tr1 = predict.gbm(object = GBM.model,newdata=train[1:end_trn,], ntrees)
pr = pr+pr1
tr = tr+tr1
}
pr = pr/n.models
tr = tr/n.modelsti
head(pr)
head(tr)
summary(GBM.model)
pr = round(pr)
tr = round(tr)
# create a function to make predictions using the trained model
predictTitanic <- function (Pclass, Sex, Age, SibSp, Parch, Fare) {
return(predict.gbm(object=GBM.model, newdata=data.frame("Pclass"=Pclass, "Sex"=Sex, "Age"=Age, "SibSp"=SibSp, "Parch"=Parch, "Fare"=Fare), 2000))
}
predictTitanic(1, "male", 20, 2, 0, 8.50)
TitanicService <- publishWebService("predictTitanic", "TitanicDemo", list("Pclass"="string", "Sex"="string", "Age"="int", "SibSp"="int", "Parch"="int", "Fare"="float"), list("survProb"="float"), wsID, wsAuth)
endpoints <- TitanicService[[2]]
endpoints
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""), list("Pclass", "Sex", "Age", "SibSp", "Parch", "Fare"), list("1", "male", "20", "2", "0", "8.50"), list("1", "female", "20", "1", "0", "8.50"))
response
demoDF <- data.frame("Pclass"=c(1,2,1), "Sex"=c("male","female","male"), "Age"=c("8","20", "30"), "Parch"=c(1,1,1), "SibSp"=c(1,3,1), "Fare"=c(10,7.5, 9))
responseDF <- consumeDataframe(TitanicService[[2]][[1]]$PrimaryKey, paste(TitanicService[[2]][[1]]$ApiLocation,"/execute?api-version=2.0&details=true",sep=""), demoDF)
responseDF
install.packages(e1071)
install.packages("e1071")
packDependencies("MSFTpredict")
recurPkg <- function(pkgName, packages) {
# if the package isn't already in the list
print(pkgName)
if (!(pkgName %in% packages)) {
# add it
packages <- c(pkgName, packages)
pkgDeps <- available.packages()
# if the package is available on a repo
if pkgName %in% row.names(available.packages()) {
# iterate through the dependencies and check if need to add them
for (pkg in strsplit(available.packages()[pkgName, "Depends"], split=", ")[[1]]) {
# filtout duplicates and R version dependencies
if (!(pkg %in% packages) && !(grepl("R \\((.*)\\)", pkg)) && (pkg %in% row.names(available.packages()))) {
# recursively call recurPkg
packages <- recurPkg(pkg, packages)
}
}
}
}
# return updated list of packages
return(packages)
}
recurPkg <- function(pkgName, packages) {
# if the package isn't already in the list
print(pkgName)
if (!(pkgName %in% packages)) {
# add it
packages <- c(pkgName, packages)
pkgDeps <- available.packages()
# if the package is available on a repo
if (pkgName %in% row.names(available.packages()) {
# iterate through the dependencies and check if need to add them
for (pkg in strsplit(available.packages()[pkgName, "Depends"], split=", ")[[1]]) {
# filtout duplicates and R version dependencies
if (!(pkg %in% packages) && !(grepl("R \\((.*)\\)", pkg)) && (pkg %in% row.names(available.packages()))) {
# recursively call recurPkg
packages <- recurPkg(pkg, packages)
}
}
}
}
# return updated list of packages
return(packages)
}
recurPkg <- function(pkgName, packages) {
# if the package isn't already in the list
print(pkgName)
if (!(pkgName %in% packages)) {
# add it
packages <- c(pkgName, packages)
pkgDeps <- available.packages()
# if the package is available on a repo
if (pkgName %in% row.names(available.packages())) {
# iterate through the dependencies and check if need to add them
for (pkg in strsplit(available.packages()[pkgName, "Depends"], split=", ")[[1]]) {
# filtout duplicates and R version dependencies
if (!(pkg %in% packages) && !(grepl("R \\((.*)\\)", pkg)) && (pkg %in% row.names(available.packages()))) {
# recursively call recurPkg
packages <- recurPkg(pkg, packages)
}
}
}
}
# return updated list of packages
return(packages)
}
packDependencies("MSFTpredict")
MSFTpredict
recurPkg <- function(pkgName, packages) {
# if the package isn't already in the list
if (!(pkgName %in% packages)) {
# add it
packages <- c(pkgName, packages)
pkgDeps <- available.packages()
# if the package is available on a repo
if (pkgName %in% row.names(available.packages())) {
# iterate through the dependencies and check if need to add them
for (pkg in strsplit(available.packages()[pkgName, "Depends"], split=", ")[[1]]) {
# filter out duplicates and R version dependencies
if (!(pkg %in% packages) && !(grepl("R \\((.*)\\)", pkg)) && (pkg %in% row.names(available.packages()))) {
# recursively call recurPkg
packages <- recurPkg(pkg, packages)
}
}
# iterate through imports
for (pkg in strsplit(available.packages()[pkgName, "Imports"], split=", ")[[1]]) {
# filter out duplicates and R version dependencies
if (!(pkg %in% packages) && !(grepl("R \\((.*)\\)", pkg)) && (pkg %in% row.names(available.packages()))) {
# recursively call recurPkg
packages <- recurPkg(pkg, packages)
}
}
}
}
# return updated list of packages
return(packages)
}
MSFTonline <- publishWebService("MSFTpredict", "MSFTdemo"), list("close"="float", "volume"="float"), list("number"="float"), wsID, wsAuth)
MSFTonline <- publishWebService("MSFTpredict", "MSFTdemo", list("close"="float", "volume"="float"), list("number"="float"), wsID, wsAuth)
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""), list("close", "volume"), list(25, 300), list(30, 100))
endpoints <- MSFTonline[[2]]
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""), list("close", "volume"), list(25, 300), list(30, 100))
response
setwd("C://Users/t-alewa/Documents/Azure-MachineLearning-ClientLibrary-R/test")
recurPkg <- function(pkgName, packages) {
# if the package isn't already in the list
if (!(pkgName %in% packages)) {
# add it
packages <- c(pkgName, packages)
pkgDeps <- available.packages()
# if the package is available on a repo
if (pkgName %in% row.names(available.packages())) {
# iterate through the dependencies and check if need to add them
for (pkg in strsplit(available.packages()[pkgName, "Depends"], split=", ")[[1]]) {
# filter out duplicates and R version dependencies
if (!(pkg %in% packages) && !(grepl("R \\((.*)\\)", pkg)) && (pkg %in% row.names(available.packages()))) {
# recursively call recurPkg
packages <- recurPkg(pkg, packages)
}
}
# iterate through imports
for (pkg in strsplit(available.packages()[pkgName, "Imports"], split=", ")[[1]]) {
# filter out duplicates and R version dependencies
if (!(pkg %in% packages) && !(grepl("R \\((.*)\\)", pkg)) && (pkg %in% row.names(available.packages()))) {
# recursively call recurPkg
packages <- recurPkg(pkg, packages)
}
}
}
}
# return updated list of packages
return(packages)
}
dataset <- read.csv(file="iris.csv")
features <- get.feature.columns(dataset)
labels   <- as.factor(get.label.column(dataset))
library(e1071)
features <- get.feature.columns(dataset)
labels   <- as.factor(get.label.column(dataset))
train.data <- data.frame(features, labels)
feature.names <- get.feature.column.names(dataset)
names(train.data) <- c(feature.names, "Class")
model <- naiveBayes(Class ~ ., train.data)
?get.feature.columns
??get.feature.columns
model <- naiveBayes(Class ~., dataset)
dataset
dataset
model <- naiveBayes(Species ~., dataset)
predict(model, data.frame(4, 4, 5, 2))
predict(model, data.frame(151, 4, 4, 5, 2))
predict(model, data.frame(151, "SepalLength" = 4, "SepalWidth" = 4, "PetalLength"=5, "PetalWidth"=2))
predict(model, data.frame(151, "SepalLength" = 4, "SepalWidth" = 4, "PetalLength"=5, "PetalWidth"=2), type="raw")
predict(model, data.frame(151, "SepalLength" = 4, "SepalWidth" = 4, "PetalLength"=5, "PetalWidth"=2), type="raw")[,2]
predicts <- predict(model, data.frame(151, "SepalLength" = 4, "SepalWidth" = 4, "PetalLength"=5, "PetalWidth"=2), type="raw")
colnames(predicts)[apply(predicts,1,which.max)]
predictClass <- function(sepalLength, sepalWidth, petalLength, petalWidth) {
predictDF <- predict(model, data.frame("sepalLength" = sepalLength, "sepalWidth" = sepalWidth, "petalLength" = petalLength, "petalWidth"=petalWidth))
colnames(predictDF)[apply(predictDF, 1, which.max)]
}
predictClass(6, 3.5, 4, 1)
predictClass <- function(sepalLength, sepalWidth, petalLength, petalWidth) {
predictDF <- predict(model, data.frame("sepalLength" = sepalLength, "sepalWidth" = sepalWidth, "petalLength" = petalLength, "petalWidth"=petalWidth), type="raw")
colnames(predictDF)[apply(predictDF, 1, which.max)]
}
predictClass(6, 3.5, 4, 1)
irisService <- publishWebService("predictClass", "irisService", list("sepalLength"="float", "sepalWidth"="float", "petalLength"="float", "petalWidth"="float"), list("class"="int"), wsID, wsAuth)
irisService
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""), list("sepalLength", "sepalWidth", "petalLength", "petalWidth"), list(5, 5, 4, 3), list(4.5, 6.5, 4.5, 2))
endpoints <- irisService[[2]]
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""), list("sepalLength", "sepalWidth", "petalLength", "petalWidth"), list(5, 5, 4, 3), list(4.5, 6.5, 4.5, 2))
endpoints <- irisService[[2]]
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""), list("sepalLength", "sepalWidth", "petalLength", "petalWidth"), list(5, 5, 4, 3), list(4.5, 6.5, 4.5, 2))
predictClass <- function(sepalLength, sepalWidth, petalLength, petalWidth) {
predictDF <- predict(model, data.frame("sepalLength" = sepalLength, "sepalWidth" = sepalWidth, "petalLength" = petalLength, "petalWidth"=petalWidth), type="raw")
colnames(predictDF)[apply(predictDF, 1, which.max)]
}
do.call(predictClass, list(5, 5, 4, 3))
do.call(predictClass, list(4.5, 6.5, 4.5, 2))
endpoints <- MSFTonline[[2]]
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""), list("close", "volume"), list(25, 300), list(30, 100))
response
irisService[[2]]
endpoints <- irisService[[2]]
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""), list("sepalLength", "sepalWidth", "petalLength", "petalWidth"), list(5, 5, 4, 3), list(4.5, 6.5, 4.5, 2))
predictClass <- function(sepalLength, sepalWidth, petalLength, petalWidth) {
predictDF <- predict(model, data.frame("sepalLength" = sepalLength, "sepalWidth" = sepalWidth, "petalLength" = petalLength, "petalWidth"=petalWidth), type="raw")
return(colnames(predictDF)[apply(predictDF, 1, which.max)])
}
irisService <- publishWebService("predictClass", "irisService", list("sepalLength"="float", "sepalWidth"="float", "petalLength"="float", "petalWidth"="float"), list("class"="int"), wsID, wsAuth)
endpoints <- irisService[[2]]
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""), list("sepalLength", "sepalWidth", "petalLength", "petalWidth"), list(5, 5, 4, 3), list(4.5, 6.5, 4.5, 2))
endpoints <- irisService[[2]]
response <- consumeDataTable(endpoints[[1]]["PrimaryKey"], paste(endpoints[[1]]["ApiLocation"], "/execute?api-version=2.0&details=true",sep=""), list("sepalLength", "sepalWidth", "petalLength", "petalWidth"), list(5, 5, 4, 3), list(4.5, 6.5, 4.5, 2))
do.call(predictClass, list(4.5, 6.5, 4.5, 2))
predictClass(6, 3.5, 4, 1)
?match.arg
getFunctionString(predictClass)
getFunctionString(MSFTpredict)
print(getFunctionString(MSFTpredict))
cat(getFunctionString(MSFTpredict))
paste(getFunctionString(MSFTpredict))
paste(getFunctionString(predictTitanic()))
paste(getFunctionString(predictTitanic)
)
paste(getFunctionString(predictClass))
getFunctionString <- function (x)
{
if (tryCatch(!is.character(x), error = function(e) TRUE))
x <- as.character(substitute(x))
objs <- list()
where <- character()
visible <- logical()
if (length(pos <- find(x, numeric = TRUE))) {
objs <- lapply(pos, function(pos, x) get(x, pos = pos),
x = x)
where <- names(pos)
visible <- rep.int(TRUE, length(pos))
}
if (length(grep(".", x, fixed = TRUE))) {
np <- length(parts <- strsplit(x, ".", fixed = TRUE)[[1L]])
for (i in 2:np) {
gen <- paste(parts[1L:(i - 1)], collapse = ".")
cl <- paste(parts[i:np], collapse = ".")
if (gen == "" || cl == "")
next
Call <- substitute(getS3method(gen, cl, TRUE), list(gen = gen,
cl = cl))
f <- eval.parent(Call)
if (!is.null(f) && !is.null(environment(f))) {
ev <- topenv(environment(f), baseenv())
nmev <- if (isNamespace(ev))
getNamespaceName(ev)
else NULL
objs <- c(objs, f)
msg <- paste("registered S3 method for", gen)
if (!is.null(nmev))
msg <- paste(msg, "from namespace", nmev)
where <- c(where, msg)
visible <- c(visible, FALSE)
}
}
}
for (i in loadedNamespaces()) {
ns <- asNamespace(i)
if (exists(x, envir = ns, inherits = FALSE)) {
f <- get(x, envir = ns, inherits = FALSE)
objs <- c(objs, f)
where <- c(where, paste("namespace", i, sep = ":"))
visible <- c(visible, FALSE)
}
}
ln <- length(objs)
dups <- rep.int(FALSE, ln)
if (ln > 1L)
for (i in 2L:ln) for (j in 1L:(i - 1L)) if (identical(objs[[i]],
objs[[j]], ignore.environment = TRUE)) {
dups[i] <- TRUE
break
}
res <- list(name = x, objs = objs, where = where, visible = visible,
dups = dups)
class(res) <- "getAnywhere"
#don't show the full response!
#res
# Might return multiple objects in a list, currently returning first object (BIG ASSUMPTION)
return(objs[1])
#return(gsub("\n", "\r\n", gsub("\"", "\\\"", objs[1])))
}
getFunctionString(MSFTpredict)
paste(getFunctionString(MSFTpredict()))
getFunctionString <- function (x)
{
if (tryCatch(!is.character(x), error = function(e) TRUE))
x <- as.character(substitute(x))
objs <- list()
where <- character()
visible <- logical()
if (length(pos <- find(x, numeric = TRUE))) {
objs <- lapply(pos, function(pos, x) get(x, pos = pos),
x = x)
where <- names(pos)
visible <- rep.int(TRUE, length(pos))
}
if (length(grep(".", x, fixed = TRUE))) {
np <- length(parts <- strsplit(x, ".", fixed = TRUE)[[1L]])
for (i in 2:np) {
gen <- paste(parts[1L:(i - 1)], collapse = ".")
cl <- paste(parts[i:np], collapse = ".")
if (gen == "" || cl == "")
next
Call <- substitute(getS3method(gen, cl, TRUE), list(gen = gen,
cl = cl))
f <- eval.parent(Call)
if (!is.null(f) && !is.null(environment(f))) {
ev <- topenv(environment(f), baseenv())
nmev <- if (isNamespace(ev))
getNamespaceName(ev)
else NULL
objs <- c(objs, f)
msg <- paste("registered S3 method for", gen)
if (!is.null(nmev))
msg <- paste(msg, "from namespace", nmev)
where <- c(where, msg)
visible <- c(visible, FALSE)
}
}
}
for (i in loadedNamespaces()) {
ns <- asNamespace(i)
if (exists(x, envir = ns, inherits = FALSE)) {
f <- get(x, envir = ns, inherits = FALSE)
objs <- c(objs, f)
where <- c(where, paste("namespace", i, sep = ":"))
visible <- c(visible, FALSE)
}
}
ln <- length(objs)
dups <- rep.int(FALSE, ln)
if (ln > 1L)
for (i in 2L:ln) for (j in 1L:(i - 1L)) if (identical(objs[[i]],
objs[[j]], ignore.environment = TRUE)) {
dups[i] <- TRUE
break
}
res <- list(name = x, objs = objs, where = where, visible = visible,
dups = dups)
class(res) <- "getAnywhere"
#don't show the full response!
#res
# Might return multiple objects in a list, currently returning first object (BIG ASSUMPTION)
#return(objs[1])
return(gsub("\n", "\r\n", gsub("\"", "\\\"", objs[1])))
}
model
as.factor(predict(model, data.frame(("sepalLength" = 5, "sepalWidth" = 6, "petalLength" = 4, "petalWidth"=3)))
as.factor(predict(model, data.frame("sepalLength" = 5, "sepalWidth" = 6, "petalLength" = 4, "petalWidth"=3)))
model <- naiveBayes(as.factor(Species) ~., dataset)
predict(model, data.frame("sepalLength" = 5, "sepalWidth" = 6, "petalLength" = 4, "petalWidth"=3)))
predict(model, data.frame("sepalLength" = 5, "sepalWidth" = 6, "petalLength" = 4, "petalWidth"=3))
?naiveBayes
predict(model, data.frame("sepalLength" = 5, "sepalWidth" = 6, "petalLength" = 4, "petalWidth"=3))[,2]
predict(model, data.frame("sepalLength" = 5, "sepalWidth" = 6, "petalLength" = 4, "petalWidth"=3))[1]
predict(model, data.frame("sepalLength" = 5, "sepalWidth" = 6, "petalLength" = 4, "petalWidth"=3))[1,2]
predict(model, data.frame("sepalLength" = 5, "sepalWidth" = 6, "petalLength" = 4, "petalWidth"=3))[1,-1]
predict(model, data.frame("sepalLength" = 5, "sepalWidth" = 6, "petalLength" = 4, "petalWidth"=3))[1]
typeof(predict(model, data.frame("sepalLength" = 5, "sepalWidth" = 6, "petalLength" = 4, "petalWidth"=3))[1])
typeof(predict(model, data.frame("sepalLength" = 5, "sepalWidth" = 6, "petalLength" = 4, "petalWidth"=3))[1]))
predict(model, data.frame("sepalLength" = 5, "sepalWidth" = 6, "petalLength" = 4, "petalWidth"=3), type="raw")
